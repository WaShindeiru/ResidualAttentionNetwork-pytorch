{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "outputId": "3c2e3ebd-6d86-4567-9372-125f92cc234f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'ResidualAttentionNetwork-pytorch'...\n",
      "remote: Enumerating objects: 202, done.\u001B[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001B[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001B[K\n",
      "remote: Total 202 (delta 10), reused 17 (delta 9), pack-reused 175 (from 1)\u001B[K\n",
      "Receiving objects: 100% (202/202), 142.61 MiB | 11.61 MiB/s, done.\n",
      "Resolving deltas: 100% (74/74), done.\n",
      "Updating files: 100% (9/9), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/WaShindeiru/ResidualAttentionNetwork-pytorch\n",
    "!mv ResidualAttentionNetwork-pytorch temp"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from temp.model.residual_attention_network import ResidualAttentionModel_92_32input_update as ResidualAttentionModel"
   ],
   "metadata": {
    "id": "Sk7KZ5Cx6uyu"
   },
   "id": "Sk7KZ5Cx6uyu",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data_mnist_train',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./data_mnist_test',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ],
   "metadata": {
    "id": "nKUVP2To-dcX"
   },
   "id": "nKUVP2To-dcX",
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "id": "Xr8BOwUl_e55"
   },
   "id": "Xr8BOwUl_e55",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "# 64, 1, 28, 28\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")"
   ],
   "metadata": {
    "id": "JT2TM7VD_kYw",
    "outputId": "f4651a9a-2957-4447-e16d-708d8382e71e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "JT2TM7VD_kYw",
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Images shape: torch.Size([32, 1, 28, 28])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class_names = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]"
   ],
   "metadata": {
    "id": "M2samDpj_tQl"
   },
   "id": "M2samDpj_tQl",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "for idx in range(5):\n",
    "    print(images[idx].shape)\n",
    "    ax = fig.add_subplot(1, 5, idx + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(images[idx].squeeze(), cmap='gray')\n",
    "    ax.set_title(class_names[labels[idx].item()])\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "GTgq54oa_vFX",
    "outputId": "11e24f12-2e4c-4e6b-f7cd-131abd868767",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    }
   },
   "id": "GTgq54oa_vFX",
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 5 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAACvCAYAAACVbcM3AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAL9lJREFUeJzt3Xt0VeWdxvEforlIEu63cEkg3KGMLRIVKxjqHYo64lRbFZxinREVllrr6MxQte1U26IMy2qdpXhFHVtUqFBEQV2Um6MNFCiXQEAEBREIRMCo2fPHLDLs930gLyGbk8v3s1bXcv/6nn12znnPu8/m7Od9m0RRFBkAAAAA1LKTUn0AAAAAABomLjYAAAAAJIKLDQAAAACJ4GIDAAAAQCK42AAAAACQCC42AAAAACSCiw0AAAAAieBiAwAAAEAiuNgAAAAAkAguNhxNmjSxm2++udp2Tz31lDVp0sQ2bdqU/EEBQD1yPOPj2LFjLT8/v9aPCQCQGo3qYuOvf/2rjR492vLy8iwjI8M6depk559/vk2dOjXx5/7FL35hr776auLPg/phw4YNduONN1r37t0tIyPDcnJy7Oyzz7YpU6bYgQMHEnnO6dOn28MPP5zIvpF6qRzfgGN16IL08P+1a9fOioqKbM6cOak+PDRwnINPrJNTfQAnyqJFi6yoqMi6du1qN9xwg3Xo0MG2bNliS5YssSlTptgtt9xyTPu79tpr7aqrrrL09PSg9r/4xS9s9OjRdtlll9Xg6NGQvP7663bllVdaenq6XXfddTZgwACrqKiwhQsX2o9//GNbtWqVPf7447X+vNOnT7eVK1faxIkTa33fSK3aHt+AE+W+++6zbt26WRRFtn37dnvqqafskksusVmzZtnIkSNTfXhogDgHn3iN5mLj5z//uTVv3tzee+89a9GiRez/27FjxzHvr2nTpta0adOjtomiyA4ePGiZmZnHvH80TKWlpXbVVVdZXl6ezZ8/3zp27Fj1/40fP95KSkrs9ddfT+ERoj6q7fENOFEuvvhiO/3006u2f/jDH1r79u3thRde4GIDtY5zcGo0mtuoNmzYYP379/dOxGZm7dq182qvvvqqDRgwwNLT061///72pz/9Kfb/q3uS8/PzbeTIkTZ37lw7/fTTLTMz0373u99ZkyZN7PPPP7enn3666ufisWPH1vJfiPrgwQcftPLycnviiSdig9whPXr0sAkTJpiZ2VdffWX333+/FRQUWHp6uuXn59vdd99tX3zxRewxr732mo0YMcJyc3MtPT3dCgoK7P7777evv/66qs25555rr7/+um3evLmqD3JffMMROr5NmzbNhg8fbu3atbP09HTr16+fPfroo95jDo1lCxcutMLCQsvIyLDu3bvbM88847VdtWqVDR8+3DIzM61z5872s5/9zCorK712If0UaNGihWVmZtrJJ///v4X++te/tiFDhljr1q0tMzPTBg0aZL///e+9xx44cMBuvfVWa9OmjWVnZ9uoUaNs69at1qRJE/vpT396Av8K1FWcg1Oj0fyykZeXZ4sXL7aVK1fagAEDjtp24cKFNmPGDLvpppssOzvb/vM//9OuuOIK+/DDD61169ZHfezatWvt6quvthtvvNFuuOEG6927tz377LM2btw4KywstB/96EdmZlZQUFBrfxvqj1mzZln37t1tyJAh1bYdN26cPf300zZ69Gi7/fbbbenSpfYf//Ef9re//c1eeeWVqnZPPfWUZWVl2W233WZZWVk2f/58+/d//3fbu3ev/epXvzIzs3vuucfKysrso48+soceesjMzLKyspL5I3HChY5vjz76qPXv399GjRplJ598ss2aNctuuukmq6ystPHjx8falpSU2OjRo+2HP/yhjRkzxp588kkbO3asDRo0yPr3729mZp988okVFRXZV199ZXfddZc1a9bMHn/8cflrbkg/ReNTVlZmO3futCiKbMeOHTZ16lQrLy+3a665pqrNlClTbNSoUfaDH/zAKioq7MUXX7Qrr7zS/vjHP9qIESOq2o0dO9b++7//26699lo788wz7Z133on9/wDn4BSJGok33ngjatq0adS0adPorLPOiu68885o7ty5UUVFRaydmUVpaWlRSUlJVW358uWRmUVTp06tqk2bNi0ys6i0tLSqlpeXF5lZ9Kc//cl7/mbNmkVjxoyp9b8L9UdZWVlkZtGll15abdvi4uLIzKJx48bF6nfccUdkZtH8+fOravv37/cef+ONN0annnpqdPDgwaraiBEjory8vBofP+qu0PFN9ZULL7ww6t69e6x2aCx79913q2o7duyI0tPTo9tvv72qNnHixMjMoqVLl8baNW/e3BsfQ/vpmDFj6KeNwKFzqPu/9PT06Kmnnoq1dftORUVFNGDAgGj48OFVtffffz8ys2jixImxtmPHjo3MLJo0aVJifwvqB87BqdNobqM6//zzbfHixTZq1Chbvny5Pfjgg3bhhRdap06dbObMmbG25513XuyXh4EDB1pOTo5t3Lix2ufp1q2bXXjhhbV+/Kj/9u7da2Zm2dnZ1badPXu2mZnddtttsfrtt99uZha7p/Twf0Xet2+f7dy508455xzbv3+/rVmz5riPG3Vf6Ph2eF859C/Kw4YNs40bN1pZWVlsn/369bNzzjmnartt27bWu3fv2Dg4e/ZsO/PMM62wsDDW7gc/+IF3jPRTKI888ojNmzfP5s2bZ88995wVFRXZuHHjbMaMGVVtDu87u3fvtrKyMjvnnHPsgw8+qKofutX5pptuiu2fyRFwCOfg1Gk0t1GZmQ0ePNhmzJhhFRUVtnz5cnvllVfsoYcestGjR1txcbH169fPzMy6du3qPbZly5a2e/fuap+jW7dutX7caBhycnLM7P8Go+ps3rzZTjrpJOvRo0es3qFDB2vRooVt3ry5qrZq1Sr713/9V5s/f37VYHqI+wUSDVfI+PbnP//ZJk2aZIsXL7b9+/fHHl9WVmbNmzev2g4ZBzdv3mxnnHGG1653795ejX4KpbCwMBYQv/rqq+2b3/ym3XzzzTZy5EhLS0uzP/7xj/azn/3MiouLY/fLN2nSpOq/D42Z7jnYHUPReHEOTp1GdbFxSFpamg0ePNgGDx5svXr1suuvv95efvllmzRpkpnZEWeZiqKo2n0z8xSOJCcnx3Jzc23lypXBjzn8ZKrs2bPHhg0bZjk5OXbfffdZQUGBZWRk2AcffGA/+clPZFAXDduRxrdrrrnGvvOd71ifPn1s8uTJ1qVLF0tLS7PZs2fbQw895PWV4xkHXfRThDrppJOsqKjIpkyZYuvXr7ddu3bZqFGjbOjQofbb3/7WOnbsaKeccopNmzbNpk+fnurDRT3COTh1GuXFxuEO/YvKxx9/nOjzVNdh0TiMHDnSHn/8cVu8eLGdddZZR2yXl5dnlZWVtn79euvbt29Vffv27bZnzx7Ly8szM7O3337bPvvsM5sxY4YNHTq0ql1paam3T/pg43P4+DZr1iz74osvbObMmbFfLRYsWFDj/efl5dn69eu9+tq1a2Pbx9JPga+++srMzMrLy+0Pf/iDZWRk2Ny5c2PrWk2bNi32mENjZmlpqfXs2bOqXlJScmIOGvUC5+DUaDSZjQULFsh/kTt0X5762b82NWvWzPbs2ZPoc6Duu/POO61Zs2Y2btw42759u/f/b9iwwaZMmWKXXHKJmZm32ujkyZPNzKpmWDn0r8+H9+2Kigr77W9/6+27WbNm/KTbQIWMb6qvlJWVeV/ajsUll1xiS5YssWXLllXVPv30U3v++edj7Y6ln6Jx+/LLL+2NN96wtLQ069u3rzVt2tSaNGkSm0Z006ZN9uqrr8Yedygr6fapqVOnJn7MqD84B6dGo/ll45ZbbrH9+/fb5Zdfbn369LGKigpbtGiRvfTSS5afn2/XX399os8/aNAge/PNN23y5MmWm5tr3bp1k/c6o2ErKCiw6dOn2/e+9z3r27dvbPXSRYsW2csvv2xjx461CRMm2JgxY+zxxx+v+pl22bJl9vTTT9tll11mRUVFZmY2ZMgQa9mypY0ZM8ZuvfVWa9KkiT377LPyi+egQYPspZdesttuu80GDx5sWVlZ9t3vfvdEvwRIQMj4tn37dktLS7Pvfve7duONN1p5ebn913/9l7Vr167Gv+zeeeed9uyzz9pFF11kEyZMqJr6Ni8vz1asWFHV7lj6KRqXOXPmVIVod+zYYdOnT7f169fbXXfdZTk5OTZixAibPHmyXXTRRfb973/fduzYYY888oj16NEj1scGDRpkV1xxhT388MP22WefVU19u27dOjNr3P+qjP/HOThFUjQL1gk3Z86c6B//8R+jPn36RFlZWVFaWlrUo0eP6JZbbom2b99e1c7MovHjx3uPz8vLi01de6Spb0eMGCGff82aNdHQoUOjzMzMyMyYBreRW7duXXTDDTdE+fn5UVpaWpSdnR2dffbZ0dSpU6umyvvyyy+je++9N+rWrVt0yimnRF26dIn+5V/+JTaVXhRF0Z///OfozDPPjDIzM6Pc3NyqaU/NLFqwYEFVu/Ly8uj73/9+1KJFi8jMGu0UfA1R6Pg2c+bMaODAgVFGRkaUn58fPfDAA9GTTz4ZPJYNGzYsGjZsWKy2YsWKaNiwYVFGRkbUqVOn6P7774+eeOIJb5+h/ZSpbxsHNfVtRkZGdNppp0WPPvpoVFlZWdX2iSeeiHr27Bmlp6dHffr0iaZNmxZNmjQpcr/CfP7559H48eOjVq1aRVlZWdFll10WrV27NjKz6Je//OWJ/hNRh3EOPrGaRBH/tAQAABqe4uJi++Y3v2nPPfecnJIZQPIaTWYDAAA0XAcOHPBqDz/8sJ100kmx8C6AE6vRZDYAAEDD9eCDD9r7779vRUVFdvLJJ9ucOXNszpw59qMf/ci6dOmS6sMDGi1uowIAAPXevHnz7N5777XVq1dbeXm5de3a1a699lq755577OST+bdVIFW42AAAAACQCDIbAAAAABIR9LtiZWWlbdu2zbKzs5mrGlWiKLJ9+/ZZbm6unXRSctet9D8oJ6r/mdEH4aP/IdU4ByOVjqX/BV1sbNu2jXAVjmjLli3WuXPnxPZP/8PRJN3/zOiDODL6H1KNczBSKaT/BV1sZGdn18oB1XWFhYVerbS01Kt9+umnXk3N3/3KK6/Etvfv338cR1d3Jd0/TkT/U/9aU5txptzc3Gr3369fP6/NgAEDvNrBgwe92vLly71a//79Y9vLli3z2qipIktKSrxaXXYi+kdjGQNx7Oh/Nde0adPY9tdff+21adu2rVe75557vNprr73m1RYsWHDU5zvSc9Y3DeEcXJvU+zxkyBCv1rVr16Num+m/vVWrVl5t7969Xs09v6rvjqtXr/Zq8+fP92p1WUj/CLrYaCw/m6nZKtRPQ+r1SEtLC2pXW45n37U9J0DS/eNE9L+kLzZUP3L3r/pfenp60HGpx7p9Ug3AqlbfpKp/AGb0v+MR8nepsTMzM9Orhcw21Zhfx7q8/9qmjjfkHJmRkeG1UTXV/7788kuv5p6r1fm8prOkJf2d5VgEfY5PwHEAAAAAaIS42AAAAACQiEa9yk2nTp1i2+3atfPaPPTQQ15NZTt++ctferULLrggtu1mOI5H6M9l6uetuvTzW11RWVlZo8cNHDjQq02YMMGrnXXWWV7tiy++qHb/6ufaU0891atVVFR4tVNOOeWo22ZmW7du9Woq2/HMM8/EtpcuXeq1Ubc71PR1BVB/hd7G4t56oh6nzpvDhg3zanfffbdX2717d2z7f/7nf4KO66uvvvJq7vgWOrZxvq25mr7mqp17DjPzz4kqD5mXlxf0nMpHH30U21b9Kj8/36uF3Jak+lBdPgfzywYAAACARHCxAQAAACARXGwAAAAASAQXGwAAAAASUe8D4ios26tXL6/mhrXN/DUGlixZ4rVRAdq//vWvXm3z5s1ezQ2e/fSnPw163KJFi7zaunXrYtuhATOCaGFUeNoNLw4aNMhrc/PNN3s1FdJ67733vFrv3r1j22pBIfX+tWjRwqvt3LnTq7l/09q1a702a9as8WrKP/zDP8S2i4uLvTYq8F6XA2sAkhG6FpA7xv7mN7/x2rzzzjvVPs7M7N577/Vqc+fOjW1feOGFXpuQMLgZ41ZtCp24pqav+aRJk7yaWnTPXYxOPd/MmTO92pgxY7yaOie6ExRkZWV5bVauXOnVrrnmGq/2wgsvxLbVYpTq+OtKX+aXDQAAAACJ4GIDAAAAQCK42AAAAACQiDqd2XDzGCp30aZNG68Wcm+omdmWLVti21deeaXX5rHHHvNqGzZs8GoTJ070am+99VZs213gxUxnBdTfWVRUFNtW99+//fbbXo3MRpiQRXT69u3r1dTrW1JS4tXUwj0ZGRmx7c8//9xroxbr27Nnj1dT92Cmp6fHttXnws0tmemcUtu2bWPbQ4cO9drMmzfPq9WV+0UBnDhqPD1w4EC1jxs8eLBXO+ecc2p8HO4CpaeffrrXRi30V5vjFudgn3pNQl6nadOmebVvf/vbXs09X5np86ube2jVqpXXxl382cxs5MiRXk1lf3Jzc2Pb+/bt89q4uREzsylTpni1+++/P7a9YsUKr82ll17q1erK+ZZfNgAAAAAkgosNAAAAAIngYgMAAABAIrjYAAAAAJCIOhMQV4EyN+yiAjibNm3yamqxExWEzczMjG2rhddOO+00r6YCPUuXLvVqbihdHasKiKsgr1vr0qWL1+aMM87wamqhQvhUENs1a9Ysr6bCix06dPBqakHAkIC4mthAHasKNLr7VwsKqQUwVVDP7aelpaVeG0V9ZpEaaox13+uQiRLU40IfGxqWVeO1GtdDFBYWejU3OKxU9/cQ/D0yd3IKM7ODBw96tauuuiq2/cEHHwTtPy0tzaupcdE956pzpAqIq3MwY9mJ97vf/S627S4ua2a2Y8cOr/bpp596Nfd8qKjHqYD4HXfc4dXUOdjtk6Hjmlqk133s8OHDvTYvvfSSV/ve977n1VKBXzYAAAAAJIKLDQAAAACJ4GIDAAAAQCK42AAAAACQiDoTEO/fv79Xc1cQVyszqyCaCuqooG15eXls+7PPPvPaqAD3xx9/HPScLhUsV49TQbS9e/fGttUq0j169PBqxcXFXk0F9VA9FQbv16+fV1Mrdqq+261bt9i2Coi7nwEzs127dgW1c99n1dfUcxYUFHg193N25plnem3U34j6JTT0rMLTNQ2gq+esaRhcefrpp73a6NGjvdqqVauqPS6ECZlww8xs1KhRse0nnngi6HGhqyK74WEVqj2e/btC+zd8vXv39moXX3xxbHvz5s1eG3eiHzP9vVC9p+5EACpErt4/FSTPycnxal988cUxH4OZ/t7p9q0tW7Z4bYYMGeLV1KQIakKjpPHLBgAAAIBEcLEBAAAAIBFcbAAAAABIBBcbAAAAABJRZwLiffv29WpuKLpdu3ZeG7XSoqICN+6KjCosq4KKKoyr2rnPqQK6+/fv9w9WcEPj6rVQIfgBAwZ4NbViKqp33333eTXVr7Zu3erV/u7v/s6rbdu2rdrnVO9pixYtvJpaHdydREAF0bp27erV1Er3bdq0iW3feuutXpvnnnvOq6HuqGlQNTQMXtNQrVoNesKECV7NDXWrlYN//OMfezU1ocJPfvITr3bdddcd9TihqfOa6gvt27f3au6Y9NZbbwU9Z+gEAm4fccexI6npZ4UweM1961vf8mruOBM67qiaWr3bbaf6ldpXq1atvJri9gf1fUFR52o3bB76GRg6dKhXIyAOAAAAoMHgYgMAAABAIrjYAAAAAJCIlGQ2unTp4tXUIizuwinqnk91r7q7WJ+Zf7+bWVimQt1Xr+6jV4vBuIuqqcepe/jU8bt/Z8+ePb027777rlfLy8vzamQ2whQWFsa2c3NzvTYqn6Hu51QLQbr3Zap7StXiWGrRR1VzP1PqM6DuZ+/YsaNXc++rb9asmdemefPmXq2srMyroX45nnyG22/UwldvvvmmV1OfNfd8oNosWLDAq6n7nzt06ODV3DFWjcPwqddXjVuXX365V1u9enW1+1fnSHW/uspLuPemq6yOos7V7veDmmaUoJ1++uleze1boQs2KyF5DLV/9R1TLaincrTu/tT3RPUZUN8F3EUPDxw44LVRf2OvXr28WirwywYAAACARHCxAQAAACARXGwAAAAASAQXGwAAAAASkZKAuFpITIVd3MXzBg4c6LVRYWcVTlPBGbemQuoqBKb2pYJFbrAtNOimgon9+vWLbauQvVogUAUy1cJGoYsjNibf+c53YtvqPVbhSBUCUwuXueFpFcRVQbHQcKQbCFfHpYLl7mKAZv7frkLwF198sVd78cUXvRrqDrfPqX4Uumib+3kxM3vssceO+nxmOmypau6kBNnZ2V4bdyFYM7MVK1Z4NTdsaWb2wAMPxLbHjx/vtTn8+FnA7f+oMUQ5++yzvdozzzxTo+dUr73qW2479d1AnSNVPyIgniw1mY37GqtzmHpPVU2dq90+o8Lm6nyrzufqOd1xLD8/P+i41L5CjkF9BtREGqnALxsAAAAAEsHFBgAAAIBEcLEBAAAAIBFcbAAAAABIROIBcRXiUystqpWM3ce2bNnSaxMS/DbTQVt3hW/VRgkNers11UYFklTIJzMzM7atQuShYd8ePXp4NQLiviFDhsS21XulwoXue2WmVxB3+1FIgM3MbN++fV5N9V13/2oCBLU6qqq5fUu9FiogTEA8NULCssezL8Vd4dvMD9Vu2rTJa/PZZ595tXPPPderucevPnsjR470am+99ZZXu/fee73a1Vdf7dWqO4bGJnQ1edWubdu2Xm3evHnVPmfoCtEh/VT1v44dO3o1FRCvTSHH2tj6mgpPf/7557FtFRBv0aKFV9u8ebNXU9+/3HOk6mvqe5WajEc91t2/mghJfa91J3dR1MQd6ljVhEypwC8bAAAAABLBxQYAAACARHCxAQAAACARXGwAAAAASETiAfG+fft6NRUaV+FVd4VlFbxVQR135XEzPwxu5gfbVPD7eLiBIbV/FXhSYeJvfOMbse3S0lKvjQoaqddaBSuXLFni1Ro7N0ivAmCq3+7evdurqf7nBtZU/wiZLOBIj3UDhmpSARUyU0E9NzCpgm6DBw/2akiN0HBpSDsVrFTUSt2FhYWxbRUGV/r16+fVPvzww9i26s+h2rRp49VatWoV27700ku9Nq+99lqNn/NECTmPqckolJBJVFQoVQX8v/Wtb1X7fGq8U88Zunq327+7dOnitWnfvr1XW7t2bbX7Vsca+h1Cfe7cWujK7A2FmjjI/Yyr1yTk3Hekx4YE9VVfU98x1feDTz75JLat+p/6vqe+V7jnfTVRjDoGNTFDKvDLBgAAAIBEcLEBAAAAIBFcbAAAAABIBBcbAAAAABKReEB82bJlXm39+vVerWfPnl6tqKgotq1CgyErJ5vpFRlDwkEVFRXVtjHTIaKargCqwsRukHzYsGFem9mzZ3u1hQsXejUVLoevc+fOsW0V5FIB/LS0NK+mQt3u6u6hgUAV7lR93p08QU1GoPblTsxg5gfi1Mr0jW3F2/qmpquKH8/7GhoId61evbpGj1Png5CVg838z98dd9zhtakPAfGQFbdDV+V2hY5RarKI559/vtrHhQZ7a0p9DwgNdYccR+j3BfiaN2/u1dwVxNX3LPX+qfOaGhtUzaXeUzWxivpMuf1Z7SsrK8urqTFr586d1R6D2n/r1q29WirwywYAAACARHCxAQAAACARXGwAAAAASETimQ1FLXqmsh1u7YEHHvDauItGmZkVFBR4NXUvqLq3vqbUPXbuPdLqnj51D+lpp53m1a677rqaHxxqZNu2bdW2UX1I3durFlx0F+VR+1L3YKq+pu7fdKmFgpo1a+bV1IJ96vhdtfl5qsuqy3olmV0JyZkd6Rhqelyhj1PH5vbL0GxbyKJzx3Mv/7p166o9DrXw3+H3P1dWVspzWar16dMntq0WJ1R/m+JmbtQ5bPv27V6tW7duXk2NK24us3fv3kH7V/fahyyQq3Kf559/vlfr1auXV3MXw1XZytB7+dVr4WYuVUawIQsZ21QbVVPjR0hOSS0SHZoJcfMlZv54p87d6jugGtvcz+KAAQO8Nur4Q88ZSeOXDQAAAACJ4GIDAAAAQCK42AAAAACQCC42AAAAACQiJQHx2qRCqSrQExKSCVng5UhU8MeljkuFltRxuMd/PKFNFl/z9e/f36u5C/GpsLYKd6mgmHrv3TBhaF8IXTgqpM+EPqd7rOrvUZ9FtVCTWjSwPknl56cuf3bVsYWMi2qMCgl/q8epALqiFhvcu3dvbNsNBJvFJx/5+uuv7f333w96vhPpn//5n2PbF110kddmx44dXk0FrN3Pr5pQQoVl1aKMaiy44oorYtu7du3y2qg+pN5nNYnFJ598EttW4127du282gUXXODV3L9Tjf0qNK7k5eV5NXfxtQcffDBoX/WRmqxEnT/c9zn0860WylPhaff9UgF/dT4sLy/3aq1atfJq7kQM7qQwR6KOw504KLSvqXFSLfRX0wVYQ/HLBgAAAIBEcLEBAAAAIBFcbAAAAABIBBcbAAAAABJR7wPiKrwTEnA9UrvaPA43zKSCvSq8ExKqDFWXA6V1yaBBg7ya+566gXGz8PdPvfduSE6F31S/UuE3FdgOofqHCrG54cvQSRjUisDLli07lkNEDdTViSFCVwAOOdaQMfdI+1Lt3NC0Chx36tSp6r9DViROhVdffTW2fcYZZ3htVIBbjVEhK4ir4O0NN9wQtP/nn38+tt2hQwevjQrCqhW43YC/mR/yV+O8G7w1M/vwww+rranzgQrQq+C9CtW/8MILXq2hUucw9R3N/Zy2b9/ea/Piiy96teHDh3s1dc5y+64ai1SYXR2r2r8bEFcTX6j+ofq8+1qoY1A1pWfPnl6NgDgAAACAeomLDQAAAACJ4GIDAAAAQCK42AAAAACQiHofEN+9e3dQu9CVJ12hq34rblhHrZCpwkEqcFcXwp0NmQomhqw6r9qo4KoKE7qBSbXyuAocrlq1yqt17dr1qMdppvuf6t+qr7m10IC4Oq76HhA//O+szc9lSH8Lfb6kx4uQY1XHEdK3QvevxvTQcV71S3csVsfVp0+fqv9WK0jXBaWlpbFttXJ3bm5u0L7c1bW3bt3qtVHnsMOD9IeUlZV5Nfdcp4KxKkytat27d/dq2dnZ1R7rwIEDvZp6zbZt2xbbVhMIqMlB3GMw00HhLVu2eLWGSr0mIRM5qGC5CjarSU7UudSl3pfQSS0Utz+ov1H1GXV+3bhxY2xbhbzV50KNiSponzR+2QAAAACQCC42AAAAACSCiw0AAAAAieBiAwAAAEAi6nRA3A3hqHDNnj17vJpaRbGmgcnQFRlrc9XvuroybUPWqlUrr+YGAFVfU8Fv1WfU6rlu2LJjx45eGxV0c0ObZjr8VlJSEttW4UgVhFRBcjf0rvqoCs117tzZq9V31Y0lIeNWXV3hW0nFsYbsP/QYDg91HzJkyBCv1rp169i2CqPu2rWr6r/VZ7ou2LRpU2xbBUl37tzp1dT45q7UrcYQ93UzM9u+fbtXe/31172aG2gtLy/32qiAqxrv1Bgesq8333yz2seZ+f1BhXjV2K/6UUhYuSFTq3K7ExuY+WOPGoveeecdr3bRRRd5NRWeds916rjU+6xWsFf7dx+rHqf6pPpeUVxcHNvOy8vz2qjJadR3UzW5QdL4ZQMAAABAIrjYAAAAAJAILjYAAAAAJKJOZzZC7slViwCp+9ZULYS6B7M2cxxqX+q+VSRL5SDcXIK6d1MtVKXuK1X3Oufn58e2VV9WQvtkmzZtYtsqn6GeUx2/mx0JvWdavWYNXZJ5BjWOqffreBa8CxG6qJXreF6b0aNHx7Yvv/xyr01hYaFXU7khlbdwx12VS3r55Zer/ruuZmxcarFQdU/43r17vVrIonhqgTZ37DHT40PI4mLqdc7JyfFqp556qldzxze1AFyvXr28mruAn5nf59WYqxaFUzkAtThiY6L6X8iCdGoMU4trtm3b1quFLgDtOp6FSN0xRLVR3xNVbtLNRoXmRtTro17/pPHLBgAAAIBEcLEBAAAAIBFcbAAAAABIBBcbAAAAABJRpwPiIVSYWgViVHCmNhfiU2Exd/8q3KmCQHV1saiGTC285Paj0CCuCmSqcLa7iJbqCypgrfqH6vMhx68C4iF9WQXk1DF07drVqzU2tbko3vGMWTU9jtpclFAtRPXYY495tQEDBng1NxQcGoLfv3+/V1N91X1tVQDz8DG8NgP3SVJhZxWmVpM+uGOBOo+qMeS9996rdl/qONR4p86bKryvJutw24X2ZRV6D3m/VXBdvWYbN26sdl8NmXpNFPe9UX1NBfBVn1HP6fYPNb6q/qHO56pPun1GHZeaVED1U/fYVOBdLbCpxroWLVp4taTxywYAAACARHCxAQAAACARXGwAAAAASAQXGwAAAAASUe8D4qFBRRXuClkFN2RVSzMd8nHDQKHhoMa46nKqqZCZ+z6HrhgbEj41C3ufQ/ufWtnXDXyqx6lQW8jnIjRsrlYSru8O/9tDA6e1Ra10r8K+mzZt8mohAe7Q8TQ04D558uTY9tVXX+212bFjh1d78cUXq933mDFjvJrq4+pzpmrHukJ0fVlBfPny5V5tyJAhXk2tru0GYdV4oSa2UBO3dOzY0auFTDyhhAaM3f6gJtdYsWJFtcdl5q+6rMZc1a9Uu5KSEv9gGxHVZxT3O9Mnn3zitVHjhwr4q8e6QieBUcdf0/EgdF/uhBVLly712lx//fVeTa1Wr84ZSeOXDQAAAACJ4GIDAAAAQCK42AAAAACQCC42AAAAACSi3gfE1YqdahXFvXv3ejU3AKjCviqIptop7v5V4FAFktRq1jjxQlbPVVQ4UoWn3bClmkBABblatmzp1VQw0Q00quC66n9qBXQ3cKcC9Sp86R5DQ1BdELCmQcGRI0d6tUmTJsW227ZtG7SvnTt3erW7777bq73xxhux7dBj79Gjh1f7wx/+4NXcgPFvfvMbr82vf/3roOe87LLLYtsTJ0702qiwqPpsqL/Tbac+G4cHh+tLQHz16tVe7bzzzvNqKsjsUucw9Tqoc7Bq544ZKoCuzrfqWNX75YZv1Tg8atQor7Zw4UKvtmfPnti2CiGHHv+GDRu8WmOiXhMVynfPM2vWrAnalzo/haw+ro5BnZdVO8Xdv+of+/fv92pqYhW3v6mJDdRYp4415LNe2/hlAwAAAEAiuNgAAAAAkAguNgAAAAAkot5nNmp6b56Zfw+7uudT3a+n2oUsvqbud1U1lUNBskIWfVR9oayszKsVFBR4tZAFAdXiPqr2zjvveLX8/Hyv1rVr19i2up9dLbQVupCgS90b2tD6cpMmTWL9Qo0r7uJLysyZM73aN77xDa/m3ie+b98+r02XLl28mrpnfvr06V7tL3/5S2z7/PPP99rceeedXu3f/u3fvNrs2bO92j/90z/Ftnfv3u21CeXes6wyAKoP1jRboT4Hh48B9SWzsX79+qB26rzm9m/Vt0MzjGr8dPev7jlX97Sr91m9X+74qe5VVxk7lZt026kxXY0H6u/evHmzV2tMVL5PfZ7c19jNgJmF5ydCFltV59vjWWTZ/ZtUX3YX3zXT/dT9nKnvuaELsKo+mTR+2QAAAACQCC42AAAAACSCiw0AAAAAieBiAwAAAEAi6n1AXAVQ1aJkKpDkUkEgFRgKDeaEBMRV4K4hLoRW16lwoRsoU/1KhdPUQnxqUUk3BKZCW25A2Mysf//+Xk0t9uY+p9r/xx9/7NVyc3O9mhtMVovGqfCeWoCwPouiKPZZDwmDK++//75XO+OMM7za22+/Hdu+/vrrg/b/q1/9yqv9/d//vVfr06dPbLukpMRroxYvu+uuu7zaI488EnRsrtBFs9zPowrLqxCoCmWGLOqXihBlEt577z2vFhqwdqlzk1osVL2+IftX758Ky6rnDAmqd+rUyaup87Ka5CMkIK76jDrWv/3tb0c9zoZOvVdqEhL3+9fKlSu9NmqSltBQtNvfVF9T3x3VvtRzun+n+vyo75hqMheXWhgydPxT5+qk8csGAAAAgERwsQEAAAAgEVxsAAAAAEgEFxsAAAAAElGnA+Ju2EUFcNQKyCrko8K9bmBNhWtUaEnVVPjNPY7QlVZrGhBXx19fVrlNtc6dO3s1N1gVuuqpep9VmDBEdasYH23/buD1yy+/9NqE9u+QfakgmgrL12fnnXde7LVwV8g284Ok6nUpLCwMej431N2iRQuvjeoj7urxZnqlWncCglatWnltLrjgAq9WXFzs1WoqdIxyP39qnA9ZpdpMf17c41CPOzxYWVlZKSdwqGtU6F9NcqI+q+5Yps4x6jUPDde7QfWQELmZ7stqfHbfQ7Uy+Pz5872aei3cz5SaHEId/6effhp0rI2JGsdU33Jrc+fO9doUFRV5NfW5DDmXqu+J6rjUZEIhk1qoz4V6ThXgdoPkf/nLX7w2SuikC0njlw0AAAAAieBiAwAAAEAiuNgAAAAAkAguNgAAAAAkok4HxEOCgyrEpwLWoUFYl1rdUR2XCny5gSR1rCpMrJ7TrTX2gFltU6sRu2FZFYpW71Xoisgh/VuFu1Q/UrXt27fHtlUotn379l5N/Z3u8asApTrWbdu2ebX6bN++fbHPtXr/XWrVYrWqswpNuu+rCnB/+OGHXm3RokVebd26dV5t1apVse01a9Z4beqKJUuWxLbVa7hx40avplZwVuOnW1Pvx5YtW6r+uz5PvqFCy+3atfNq7mQHigreqpp6vdwxI3SSFjWWqdCr+3lRqy7PmDHDq6kJHHr06BHbVgFxdQw1nfClIVPvnzqHue+9Orf+/ve/92pPPvmkV9u5c6dXc4Pe6v1TYfDQ0LVbU58B1T9Uu8PHHjOzTZs2eW0UdfypmLiFXzYAAAAAJIKLDQAAAACJ4GIDAAAAQCK42AAAAACQiDodEA+hQkUqEBOygrMKEqogjQoClZWVVVtTq56qgLgKDNV0BWqEue6667xaaWlpbFuFnffu3evVQkKVZn4ILLQvhPbvnJycoz6fmdnu3bu9mgp3uvtS4dnWrVt7tWnTpnm1+mzp0qWx7YsvvjhFR9JwhEzUYeYHIs8999zaP5hGQp2v1EQGISuBq3ElJAxuFrZieOi5T/WjXbt2xbZ79+7ttfn5z38etH+10rNLvV7uxAbQ503VZ9xz4kcffeS1UZO7qL7WuXNnr9amTZvYtprwQ63mrc7Vqn+4/U99B1STx7hhcDP9mXWpVcXV99VUTG7BN1gAAAAAieBiAwAAAEAiuNgAAAAAkIh6n9l49913vdro0aO9mrqf3F28TOU/3HvVzfR99Kqdew+pujcvNzfXq61du9arHTx40Ku56vMiU6mmFkZ79NFHY9vZ2dlemyFDhni1rKwsr7Z//36v5t5LqbIe6h7gHTt2eDWVLXIXtNqzZ4/XRi3kpe6Rdu9lveWWW7w26v7refPmeTUAyXEzXWqRTnWO+fa3v+3V3IXr1NimqHOdus+9pllKtX+1L/cc7C50aqb/JnWsIcegvhu4C2ceiXv8oVmm+kjlJ1q2bFnt41RfCKXyHqpWn6nPgMqcqMxl0vhlAwAAAEAiuNgAAAAAkAguNgAAAAAkgosNAAAAAImo9wFxFfh65JFHvJoKybihWrVYWocOHYKOQwWA3VB3RUWF1yZkMUAkT4XxbrrppmofpxbpueKKK7xaQUGBV2vfvn1su1+/fl6btm3bejUV7lSL87mBcPVZUYsHzZgxw6tt3brVqwGoe0LCzZMnT/ZqKiDuClnY7khCFghUoWs1cYvaV0igWk1iEXq+db8vqElh1Bj72muvBe2/IQfCXcXFxV7thRde8Gru96rQsL3qHyET6KjFAJWaTsaj9h+6AKb6bLjWr1/v1dTkN4sXL652X7WNXzYAAAAAJIKLDQAAAACJ4GIDAAAAQCKCMhsNYbE49Te490iqeyZD7pM7UruQ/TfU17Y+7f94qGNT2Ry1KKO7YJa6H1otEuU+zkxnhtx26hjUsda3e4dPRP+oy30QqVXX+l9IW/UZV4uKukLvaVdqmtlQixKGLOAXegxqDAw5NpWNUWPziRhP69s5WL0m6rVzz1mhx6Ha1ebfUFf3pb4HqM/U8SyOqATlYaKAVh999JF16dKlVg4KDc+WLVvkiqC1hf6Ho0m6/5nRB3Fk9D+kGudgpFJI/wu62KisrLRt27ZZdnb2cf3LBhqWKIps3759lpubK/+lqbbQ/6CcqP5nRh+Ej/6HVOMcjFQ6lv4XdLEBAAAAAMeKgDgAAACARHCxAQAAACARXGwAAAAASAQXGwAAAAASwcUGAAAAgERwsQEAAAAgEVxsAAAAAEjE/wKMik+eNlqSfQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResidualAttentionModel().to(device)\n",
    "# print(model)\n",
    "\n",
    "lr = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "total_epochs = 10\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    model.train()\n",
    "    epoch_start = time.time()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{total_epochs}\", leave=False)\n",
    "\n",
    "    for images, labels in train_loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{total_epochs}] | \"\n",
    "        f\"Loss: {running_loss / len(train_loader):.4f} | \"\n",
    "        f\"Val Acc: {val_acc:.2f}% | \"\n",
    "        f\"Time: {epoch_time:.2f}s\"\n",
    "    )"
   ],
   "metadata": {
    "id": "MAtWrID2_yhy",
    "outputId": "aef87f5a-3e9b-40d1-a040-34fef3fb8b41",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "id": "MAtWrID2_yhy",
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 3, 3, 3], expected input[32, 1, 28, 28] to have 3 channels, but got 1 channels instead",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-32-5f9490be8eb3>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     30\u001B[0m         \u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 32\u001B[0;31m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     33\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compiled_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[misc]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1738\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1739\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1740\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1741\u001B[0m     \u001B[0;31m# torchrec tests the code consistency with the following code\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1748\u001B[0m                 \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1749\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1751\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1752\u001B[0m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/temp/model/residual_attention_network.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    254\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    255\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 256\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    257\u001B[0m         \u001B[0;31m# out = self.mpool1(out)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    258\u001B[0m         \u001B[0;31m# print(out.data)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compiled_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[misc]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1738\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1739\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1740\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1741\u001B[0m     \u001B[0;31m# torchrec tests the code consistency with the following code\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1748\u001B[0m                 \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1749\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1751\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1752\u001B[0m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    248\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    249\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 250\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    251\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compiled_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[misc]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1738\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1739\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1740\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1741\u001B[0m     \u001B[0;31m# torchrec tests the code consistency with the following code\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1748\u001B[0m                 \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1749\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1751\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1752\u001B[0m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    552\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    553\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 554\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    555\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    556\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    547\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroups\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    548\u001B[0m             )\n\u001B[0;32m--> 549\u001B[0;31m         return F.conv2d(\n\u001B[0m\u001B[1;32m    550\u001B[0m             \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpadding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdilation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroups\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    551\u001B[0m         )\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Given groups=1, weight of size [32, 3, 3, 3], expected input[32, 1, 28, 28] to have 3 channels, but got 1 channels instead"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "# from model.residual_attention_network_pre import ResidualAttentionModel\n",
    "# based https://github.com/liudaizong/Residual-Attention-Network\n",
    "from temp.model.residual_attention_network import ResidualAttentionModel_92_32input_update as ResidualAttentionModel\n",
    "\n",
    "model_file = './temp/model_92_sgd.pkl'\n",
    "\n",
    "\n",
    "# for test\n",
    "def test(model, test_loader, btrain=False, model_file='./temp/model_92_sgd.pkl'):\n",
    "    # Test\n",
    "    if not btrain:\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    #\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "        #\n",
    "        c = (predicted == labels.data).squeeze()\n",
    "        for i in range(20):\n",
    "            label = labels.data[i]\n",
    "            class_correct[label] += c[i]\n",
    "            class_total[label] += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images: %d %%' % (100 * float(correct) / total))\n",
    "    print('Accuracy of the model on the test images:', float(correct)/total)\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# Image Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop((32, 32), padding=4),   #left, top, right, bottom\n",
    "    # transforms.Scale(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# when image is rgb, totensor do the division 255\n",
    "# CIFAR-10 Dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data_mnist/',\n",
    "                               train=True,\n",
    "                               transform=transform,\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./data_mnist/',\n",
    "                              train=False,\n",
    "                              transform=test_transform)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64, # 64\n",
    "                                           shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=20,\n",
    "                                          shuffle=False)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "# 64, 1, 28, 28\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "model = ResidualAttentionModel().cuda()\n",
    "print(model)\n",
    "\n",
    "lr = 0.1  # 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "is_train = True\n",
    "is_pretrain = False\n",
    "acc_best = 0\n",
    "total_epoch = 300\n",
    "if is_train is True:\n",
    "    if is_pretrain == True:\n",
    "        model.load_state_dict((torch.load(model_file)))\n",
    "    # Training\n",
    "    for epoch in range(total_epoch):\n",
    "        model.train()\n",
    "        tims = time.time()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = Variable(images.cuda())\n",
    "            # print(images.data_mnist)\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(\"hello\")\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(\"Epoch [%d/%d], Iter [%d/%d] Loss: %.4f\" % (epoch+1, total_epoch, i+1, len(train_loader), loss.item()))\n",
    "        print('the epoch takes time:',time.time()-tims)\n",
    "        print('evaluate test set:')\n",
    "        acc = test(model, test_loader, btrain=True)\n",
    "        if acc > acc_best:\n",
    "            acc_best = acc\n",
    "            print('current best acc,', acc_best)\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "        # Decaying Learning Rate\n",
    "        if (epoch+1) / float(total_epoch) == 0.3 or (epoch+1) / float(total_epoch) == 0.6 or (epoch+1) / float(total_epoch) == 0.9:\n",
    "            lr /= 10\n",
    "            print('reset learning rate to:', lr)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "                print(param_group['lr'])\n",
    "            # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            # optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "    # Save the Model\n",
    "    torch.save(model.state_dict(), 'last_model_92_sgd.pkl')\n",
    "\n",
    "else:\n",
    "    test(model, test_loader, btrain=False)\n",
    "\n"
   ],
   "metadata": {
    "id": "zoBPNzTC6p7B",
    "outputId": "7766d978-012c-46da-aa6a-fb6ed803b6ac",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "id": "zoBPNzTC6p7B",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Images shape: torch.Size([64, 3, 32, 32])\n",
      "Labels shape: torch.Size([64])\n",
      "ResidualAttentionModel_92_32input_update(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (residual_block1): ResidualBlock(\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (conv4): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (attention_module1): AttentionModule_stage1_cifar(\n",
      "    (first_residual_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (trunk_branches): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (down_residual_blocks1): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (skip1_connection_residual_block): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (mpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (middle_2r_blocks): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (interpolation1): UpsamplingBilinear2d(size=(16, 16), mode='bilinear')\n",
      "    (up_residual_blocks1): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (interpolation2): UpsamplingBilinear2d(size=(32, 32), mode='bilinear')\n",
      "    (conv1_1_blocks): Sequential(\n",
      "      (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (6): Sigmoid()\n",
      "    )\n",
      "    (last_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (residual_block2): ResidualBlock(\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (conv4): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (attention_module2): AttentionModule_stage2_cifar(\n",
      "    (first_residual_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (trunk_branches): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (middle_2r_blocks): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (interpolation1): UpsamplingBilinear2d(size=(16, 16), mode='bilinear')\n",
      "    (conv1_1_blocks): Sequential(\n",
      "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (6): Sigmoid()\n",
      "    )\n",
      "    (last_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (attention_module2_2): AttentionModule_stage2_cifar(\n",
      "    (first_residual_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (trunk_branches): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (middle_2r_blocks): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (interpolation1): UpsamplingBilinear2d(size=(16, 16), mode='bilinear')\n",
      "    (conv1_1_blocks): Sequential(\n",
      "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (6): Sigmoid()\n",
      "    )\n",
      "    (last_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (residual_block3): ResidualBlock(\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (conv4): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (attention_module3): AttentionModule_stage3_cifar(\n",
      "    (first_residual_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (trunk_branches): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (middle_2r_blocks): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (conv1_1_blocks): Sequential(\n",
      "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (6): Sigmoid()\n",
      "    )\n",
      "    (last_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (attention_module3_2): AttentionModule_stage3_cifar(\n",
      "    (first_residual_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (trunk_branches): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (middle_2r_blocks): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (conv1_1_blocks): Sequential(\n",
      "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (6): Sigmoid()\n",
      "    )\n",
      "    (last_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (attention_module3_3): AttentionModule_stage3_cifar(\n",
      "    (first_residual_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (trunk_branches): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (middle_2r_blocks): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (conv1_1_blocks): Sequential(\n",
      "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (6): Sigmoid()\n",
      "    )\n",
      "    (last_blocks): ResidualBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (residual_block4): ResidualBlock(\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (conv4): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (residual_block5): ResidualBlock(\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (residual_block6): ResidualBlock(\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (mpool2): Sequential(\n",
      "    (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  )\n",
      "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-2ccb304fc40a>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    107\u001B[0m         \u001B[0mtims\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 109\u001B[0;31m             \u001B[0mimages\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mVariable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    110\u001B[0m             \u001B[0;31m# print(images.data)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    111\u001B[0m             \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mVariable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
